{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# ignore deprecation warnings in sklearn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Specify data directory\n",
    "\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()),'Data')\n",
    "\n",
    "# Set model directory\n",
    "\n",
    "model_dir = os.path.join(os.path.dirname(os.getcwd()), 'Model')\n",
    "\n",
    "# Set data paths\n",
    "\n",
    "train_path = os.path.join(data_dir, 'train.csv')\n",
    "\n",
    "train_processed_path = os.path.join(data_dir, 'interim', 'train_preprocessed.txt')\n",
    "\n",
    "meta_feat_path = os.path.join(data_dir, 'interim', 'meta_feat.txt')\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "train_processed = pd.read_json(train_processed_path)\n",
    "dense_feat = pd.read_json(meta_feat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "import tensorflow.keras.backend as K\n",
    "import re\n",
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN-LSTM Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Length grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_dim = np.arange(10,300,10)\n",
    "sample_size = 250\n",
    "f1_grid = {}\n",
    "history_grid = {}\n",
    "for max_length in max_length_dim:\n",
    "    \n",
    "    # Get samples\n",
    "    c0 = train_processed[train_processed.sentiment == 0][0:sample_size]\n",
    "    c1 = train_processed[train_processed.sentiment == 1][0:sample_size]\n",
    "    c2 = train_processed[train_processed.sentiment == 2][0:sample_size]\n",
    "    train_sample = pd.concat([c0, c1, c2])\n",
    "    \n",
    "    # Build model input\n",
    "    max_features = 2000\n",
    "    tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "    tokenizer.fit_on_texts(train_sample['text'].values)\n",
    "\n",
    "    X = tokenizer.texts_to_sequences(train_sample['text'].values)\n",
    "    X = pad_sequences(X, maxlen = max_length)\n",
    "    y = to_categorical(train_sample['sentiment'].values)\n",
    "\n",
    "    # Derive X and y\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, random_state = 42)\n",
    "    print(Xtrain.shape,ytrain.shape)\n",
    "    print(Xtest.shape,ytest.shape)\n",
    "    \n",
    "    # Build NN Layers \n",
    "    embed_dim = 32\n",
    "    lstm_out = 100\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, \n",
    "                        embed_dim, \n",
    "                        input_length = X.shape[1], \n",
    "                        dropout=0.2))\n",
    "    model.add(LSTM(lstm_out, \n",
    "                   dropout_U=0.2,\n",
    "                   dropout_W=0.2))\n",
    "    model.add(Dense(3,\n",
    "                    activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy', f1])\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Training\n",
    "    batch_size = 8\n",
    "    num_epochs = 5\n",
    "    Xvalid, yvalid = Xtrain[:batch_size], ytrain[:batch_size]\n",
    "    Xtrain1, ytrain1 = Xtrain[batch_size:], ytrain[batch_size:]\n",
    "    model.fit(Xtrain1, \n",
    "              ytrain1, \n",
    "              validation_data=(Xvalid, yvalid), \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs,\n",
    "              verbose = 0,\n",
    "              callbacks = [TQDMNotebookCallback()])\n",
    "    \n",
    "    # Visualizing\n",
    "    scores = model.evaluate(Xtest, ytest, verbose=10)\n",
    "    ypred = model.predict(Xtest)\n",
    "    ypred_df = pd.DataFrame(ypred)\n",
    "    ypred_max = ypred_df.apply(max, axis = 1)\n",
    "    for index, row in ypred_df.iterrows():\n",
    "        for label, item in row.items():\n",
    "            if item == ypred_max[index]:\n",
    "                row[label] = 1\n",
    "            else:\n",
    "                row[label] = 0\n",
    "    print(ypred_df.head())\n",
    "    plt.bar(x = [0,1,2],\n",
    "       height = [np.sum(np.round(ypred_df[0])), np.sum(np.round(ypred_df[1])), np.sum(np.round(ypred_df[2]))])\n",
    "    plt.xticks([0,1,2])\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluating\n",
    "    f1_s = f1_score(ytest, ypred_df, average = 'macro')\n",
    "    f1_grid[max_length] = f1_s\n",
    "    history_grid[max_length] = model.history\n",
    "    print(\"F1-SCORE for max length of %d is %f\"  % (max_length, f1_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame.from_dict(f1_grid, orient = 'index').plot(legend = None)\n",
    "plt.title('F1_score across maximum length')\n",
    "plt.xlabel('Sample sizes')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = 'f1_vs_maxlen_250samplesize_5epoch_8batchsize.sav'\n",
    "pd.DataFrame.from_dict(f1_grid, orient = 'index').to_pickle(os.path.join(model_dir, 'rnn', filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = 'f1_vs_samplesizes_50maxlen_20epoch.sav'\n",
    "gs = pickle.load(open(os.path.join(model_dir, 'rnn', filename), 'rb'))\n",
    "gs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of epoch grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch_dim = [5,10,15,20,25]\n",
    "max_length = 90\n",
    "sample_size = 250\n",
    "f1_grid = {}\n",
    "history_grid = {}\n",
    "for num_epoch in num_epoch_dim:\n",
    "    \n",
    "    # Get samples\n",
    "    c0 = train_processed[train_processed.sentiment == 0][0:sample_size]\n",
    "    c1 = train_processed[train_processed.sentiment == 1][0:sample_size]\n",
    "    c2 = train_processed[train_processed.sentiment == 2][0:sample_size]\n",
    "    train_sample = pd.concat([c0, c1, c2])\n",
    "    \n",
    "    # Build model input\n",
    "    max_features = 2000\n",
    "    tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "    tokenizer.fit_on_texts(train_sample['text'].values)\n",
    "\n",
    "    X = tokenizer.texts_to_sequences(train_sample['text'].values)\n",
    "    X = pad_sequences(X, maxlen = max_length)\n",
    "    y = to_categorical(train_sample['sentiment'].values)\n",
    "\n",
    "    # Derive X and y\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, random_state = 42)\n",
    "    print(Xtrain.shape,ytrain.shape)\n",
    "    print(Xtest.shape,ytest.shape)\n",
    "    \n",
    "    # Build NN Layers \n",
    "    embed_dim = 32\n",
    "    lstm_out = 100\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, \n",
    "                        embed_dim, \n",
    "                        input_length = X.shape[1], \n",
    "                        dropout=0.2))\n",
    "    model.add(LSTM(lstm_out, \n",
    "                   dropout_U=0.2,\n",
    "                   dropout_W=0.2))\n",
    "    model.add(Dense(3,\n",
    "                    activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy', f1])\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Training\n",
    "    batch_size = 8\n",
    "    num_epochs = num_epoch\n",
    "    Xvalid, yvalid = Xtrain[:batch_size], ytrain[:batch_size]\n",
    "    Xtrain1, ytrain1 = Xtrain[batch_size:], ytrain[batch_size:]\n",
    "    model.fit(Xtrain1, \n",
    "              ytrain1, \n",
    "              validation_data=(Xvalid, yvalid), \n",
    "              batch_size=batch_size, \n",
    "              epochs=num_epochs,\n",
    "              verbose = 0,\n",
    "              callbacks = [TQDMNotebookCallback()])\n",
    "    \n",
    "    # Visualizing\n",
    "    scores = model.evaluate(Xtest, ytest, verbose=10)\n",
    "    ypred = model.predict(Xtest)\n",
    "    ypred_df = pd.DataFrame(ypred)\n",
    "    ypred_max = ypred_df.apply(max, axis = 1)\n",
    "    for index, row in ypred_df.iterrows():\n",
    "        for label, item in row.items():\n",
    "            if item == ypred_max[index]:\n",
    "                row[label] = 1\n",
    "            else:\n",
    "                row[label] = 0\n",
    "    print(ypred_df.head())\n",
    "    plt.bar(x = [0,1,2],\n",
    "       height = [np.sum(np.round(ypred_df[0])), np.sum(np.round(ypred_df[1])), np.sum(np.round(ypred_df[2]))])\n",
    "    plt.xticks([0,1,2])\n",
    "    plt.show()\n",
    "    \n",
    "    # Evaluating\n",
    "    f1_s = f1_score(ytest, ypred_df, average = 'macro')\n",
    "    f1_grid[num_epoch] = f1_s\n",
    "    history_grid[num_epoch] = model.history\n",
    "    print(\"F1-SCORE for num epoch of %d is %f\"  % (num_epoch, f1_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(f1_grid, orient = 'index').plot(legend = None)\n",
    "plt.title('F1_score across maximum length')\n",
    "plt.xlabel('Sample sizes')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filename = 'f1_vs_nepoch_90maxlen_250samplesize.sav'\n",
    "pd.DataFrame.from_dict(f1_grid, orient = 'index').to_pickle(os.path.join(model_dir, 'rnn', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
